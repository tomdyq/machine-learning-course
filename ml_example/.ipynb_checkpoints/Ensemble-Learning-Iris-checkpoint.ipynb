{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning with Iris\n",
    "\n",
    "Analytics Vidhya threw open a data hackathon for the 8th and 9th August weekend.\n",
    "Details can be found [here](http://discuss.analyticsvidhya.com/t/online-hackathon-3-0-find-the-next-brain-wong/2838)\n",
    "This is my attempt to generate some benchmarks - with no(to minimal) feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-005af8eba5e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# test = pd.read_csv(\"Data/Test.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1815\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 1816\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   1817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((a,))\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1815\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 1816\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   1817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "#Read the train and test datasets\n",
    "# train = pd.read_csv(\"Data/Train.csv\")\n",
    "# test = pd.read_csv(\"Data/Test.csv\")\n",
    "iris = load_iris()\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "        iris.data, iris.target, test_size=0.4, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34397, 27) (22950, 27)\n"
     ]
    }
   ],
   "source": [
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Most of the columns are categorical variables.\n",
    "#Convert them to numeric using sklearn's preprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [train, test]\n",
    "input = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the following columns:\n",
    "#ID, latitude, longtitude, city, zip\n",
    "\n",
    "input.drop(input.columns[[0,1,2,4,6]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var4</th>\n",
       "      <th>institute_state</th>\n",
       "      <th>Var8</th>\n",
       "      <th>institute_country</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var14</th>\n",
       "      <th>Var15</th>\n",
       "      <th>...</th>\n",
       "      <th>project_subject</th>\n",
       "      <th>subject_area</th>\n",
       "      <th>secondary_subject</th>\n",
       "      <th>secondary_area</th>\n",
       "      <th>Resource_Category</th>\n",
       "      <th>Resource_Sub_Category</th>\n",
       "      <th>Var23</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Similar_Project_Valuation_other_institute</th>\n",
       "      <th>Project_Valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA01</td>\n",
       "      <td>TX</td>\n",
       "      <td>HXYD</td>\n",
       "      <td>Harris</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Environmental Science</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>O141</td>\n",
       "      <td>BB</td>\n",
       "      <td>D</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA03</td>\n",
       "      <td>IN</td>\n",
       "      <td>HXYD</td>\n",
       "      <td>Elkhart</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXC</td>\n",
       "      <td>...</td>\n",
       "      <td>Early Development</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>E41</td>\n",
       "      <td>BB</td>\n",
       "      <td>D</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA02</td>\n",
       "      <td>NC</td>\n",
       "      <td>HXYC</td>\n",
       "      <td>Cabarrus</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>F51</td>\n",
       "      <td>BB</td>\n",
       "      <td>A</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA02</td>\n",
       "      <td>AL</td>\n",
       "      <td>HXYM</td>\n",
       "      <td>Cullman</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Technology</td>\n",
       "      <td>N131</td>\n",
       "      <td>AA</td>\n",
       "      <td>A</td>\n",
       "      <td>226</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SA01</td>\n",
       "      <td>SC</td>\n",
       "      <td>HXYF</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>G61</td>\n",
       "      <td>AA</td>\n",
       "      <td>B</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var4 institute_state  Var8 institute_country Var10 Var11 Var12 Var13 Var14  \\\n",
       "0  SA01              TX  HXYD            Harris     N     N     N     N     N   \n",
       "1  SA03              IN  HXYD           Elkhart     N     N     N     N     N   \n",
       "2  SA02              NC  HXYC          Cabarrus     N     N     N     N     N   \n",
       "3  SA02              AL  HXYM           Cullman     N     N     N     N     N   \n",
       "4  SA01              SC  HXYF        Greenville     N     N     N     N     N   \n",
       "\n",
       "   Var15        ...               project_subject         subject_area  \\\n",
       "0  HAXXF        ...         Environmental Science       Math & Science   \n",
       "1  HAXXC        ...             Early Development     Applied Learning   \n",
       "2  HAXXF        ...          Literature & Writing  Literacy & Language   \n",
       "3  HAXXF        ...          Literature & Writing  Literacy & Language   \n",
       "4  HAXXF        ...                      Literacy  Literacy & Language   \n",
       "\n",
       "  secondary_subject       secondary_area Resource_Category  \\\n",
       "0               NaN                  NaN        Technology   \n",
       "1          Literacy  Literacy & Language          Supplies   \n",
       "2          Literacy  Literacy & Language          Supplies   \n",
       "3       Mathematics       Math & Science        Technology   \n",
       "4               ESL  Literacy & Language             Books   \n",
       "\n",
       "  Resource_Sub_Category Var23 Var24 Similar_Project_Valuation_other_institute  \\\n",
       "0                  O141    BB     D                                       253   \n",
       "1                   E41    BB     D                                       246   \n",
       "2                   F51    BB     A                                       183   \n",
       "3                  N131    AA     A                                       226   \n",
       "4                   G61    AA     B                                       266   \n",
       "\n",
       "  Project_Valuation  \n",
       "0               202  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3               916  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Two approaches to solving this.\n",
    "###*One approach*: Directly predict the project valuation\n",
    "###*Another approach*: Since a lot of the project valuation are 0, first predict probability of project valuation to be greater than 0, and if it is greater than 0, what is the project valuation. Second approach involves: first level of classification and second level of regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input['pv_code'] = 0\n",
    "input.loc[input['Project_Valuation']>0, 'pv_code'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var4</th>\n",
       "      <th>institute_state</th>\n",
       "      <th>Var8</th>\n",
       "      <th>institute_country</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var14</th>\n",
       "      <th>Var15</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_area</th>\n",
       "      <th>secondary_subject</th>\n",
       "      <th>secondary_area</th>\n",
       "      <th>Resource_Category</th>\n",
       "      <th>Resource_Sub_Category</th>\n",
       "      <th>Var23</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Similar_Project_Valuation_other_institute</th>\n",
       "      <th>Project_Valuation</th>\n",
       "      <th>pv_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA01</td>\n",
       "      <td>TX</td>\n",
       "      <td>HXYD</td>\n",
       "      <td>Harris</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>O141</td>\n",
       "      <td>BB</td>\n",
       "      <td>D</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA03</td>\n",
       "      <td>IN</td>\n",
       "      <td>HXYD</td>\n",
       "      <td>Elkhart</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXC</td>\n",
       "      <td>...</td>\n",
       "      <td>Applied Learning</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>E41</td>\n",
       "      <td>BB</td>\n",
       "      <td>D</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA02</td>\n",
       "      <td>NC</td>\n",
       "      <td>HXYC</td>\n",
       "      <td>Cabarrus</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>F51</td>\n",
       "      <td>BB</td>\n",
       "      <td>A</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA02</td>\n",
       "      <td>AL</td>\n",
       "      <td>HXYM</td>\n",
       "      <td>Cullman</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Technology</td>\n",
       "      <td>N131</td>\n",
       "      <td>AA</td>\n",
       "      <td>A</td>\n",
       "      <td>226</td>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SA01</td>\n",
       "      <td>SC</td>\n",
       "      <td>HXYF</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>HAXXF</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>G61</td>\n",
       "      <td>AA</td>\n",
       "      <td>B</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var4 institute_state  Var8 institute_country Var10 Var11 Var12 Var13 Var14  \\\n",
       "0  SA01              TX  HXYD            Harris     N     N     N     N     N   \n",
       "1  SA03              IN  HXYD           Elkhart     N     N     N     N     N   \n",
       "2  SA02              NC  HXYC          Cabarrus     N     N     N     N     N   \n",
       "3  SA02              AL  HXYM           Cullman     N     N     N     N     N   \n",
       "4  SA01              SC  HXYF        Greenville     N     N     N     N     N   \n",
       "\n",
       "   Var15   ...           subject_area secondary_subject       secondary_area  \\\n",
       "0  HAXXF   ...         Math & Science               NaN                  NaN   \n",
       "1  HAXXC   ...       Applied Learning          Literacy  Literacy & Language   \n",
       "2  HAXXF   ...    Literacy & Language          Literacy  Literacy & Language   \n",
       "3  HAXXF   ...    Literacy & Language       Mathematics       Math & Science   \n",
       "4  HAXXF   ...    Literacy & Language               ESL  Literacy & Language   \n",
       "\n",
       "  Resource_Category Resource_Sub_Category Var23 Var24  \\\n",
       "0        Technology                  O141    BB     D   \n",
       "1          Supplies                   E41    BB     D   \n",
       "2          Supplies                   F51    BB     A   \n",
       "3        Technology                  N131    AA     A   \n",
       "4             Books                   G61    AA     B   \n",
       "\n",
       "  Similar_Project_Valuation_other_institute Project_Valuation pv_code  \n",
       "0                                       253               202       1  \n",
       "1                                       246                 0       0  \n",
       "2                                       183                 0       0  \n",
       "3                                       226               916       1  \n",
       "4                                       266                 0       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace missing values with NA\n",
    "input.fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert categorical to numeric\n",
    "for i in range(20):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(input[:,i]))\n",
    "    input[:, i] = lbl.transform(input[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train, test and target labels datasets\n",
    "xgtrain, label_prob, label_pv = input[0:train.shape[0], 0:21], input[0:train.shape[0], 22], input[0:train.shape[0], 21]\n",
    "xgtest = input[train.shape[0]:,0:21]\n",
    "\n",
    "xgtrain = xgtrain.astype(float)\n",
    "label_prob = label_prob.astype(float)\n",
    "label_pv = label_pv.astype(float)\n",
    "xgtest = xgtest.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# First Approach - Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##First model: xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"min_child_weight\"] = 3\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 1\n",
    "params[\"silent\"] = 0\n",
    "params[\"max_depth\"] = 4\n",
    "params[\"nthread\"] = 6\n",
    "params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.005\n",
    "params[\"base_score\"] = 0.1\n",
    "params[\"eval_metric\"] = \"auc\"\n",
    "params[\"seed\"] = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plst = list(params.items())\n",
    "num_rounds = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain_pv = xgb.DMatrix(xgtrain, label=label_pv)\n",
    "watchlist = [(xgtrain_pv, 'train')]\n",
    "model_1_xgboost = xgb.train(plst, xgtrain_pv, num_rounds)\n",
    "model_1_predict = model_1_xgboost.predict(xgb.DMatrix(xgtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print max(model_1_predict), min(model_1_predict)\n",
    "model_1_predict[model_1_predict<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_1 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_1_predict})\n",
    "print prediction_1.head()\n",
    "prediction_1.to_csv('Submission/model_1.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse on leaderboard: 518"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 2: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_rf = RandomForestRegressor(n_estimators=400, max_depth=8, oob_score=True, n_jobs=6, random_state=123)\n",
    "model_2_rf.fit(xgtrain, label_pv)\n",
    "model_2_rf.oob_score_\n",
    "model_2_predict = model_2_rf.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_2 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_2_predict})\n",
    "print prediction_2.head()\n",
    "prediction_2.to_csv('Submission/model_2.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse on leaderboard: 842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 3: ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_3_et = ExtraTreesRegressor(n_estimators=750, max_depth=8, oob_score=True, n_jobs=6, random_state=123, verbose=1, bootstrap=True)\n",
    "model_3_et.fit(xgtrain, label_pv)\n",
    "model_3_predict = model_3_et.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_3 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_3_predict})\n",
    "print prediction_3.head()\n",
    "prediction_3.to_csv('Submission/model_3.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse on leaderboard: 497.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Creating dummies instead of numeric encoding of categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Begin data prep\n",
    "frames = [train, test]\n",
    "input2 = pd.concat(frames)\n",
    "\n",
    "#Drop the following columns:\n",
    "#ID, latitude, longtitude, city, zip\n",
    "\n",
    "input2.drop(input2.columns[[0,1,2,4,6]], axis=1, inplace=True)\n",
    "\n",
    "#sanity check\n",
    "input2.head()\n",
    "\n",
    "input2['pv_code'] = 0\n",
    "input2.loc[input2['Project_Valuation']>0, 'pv_code'] = 1\n",
    "\n",
    "input2.head()\n",
    "\n",
    "#Replace missing values with NA\n",
    "input2.fillna(\"NA\", inplace=True)\n",
    "\n",
    "input2.ix[:,:21].head()\n",
    "input2.loc[input2.Project_Valuation==\"NA\",\"Project_Valuation\"] = 0\n",
    "input2.Project_Valuation = input2.Project_Valuation.astype(float)\n",
    "input2.dtypes\n",
    "#input2_dummy = pd.get_dummies(input2.ix[:,:21], dummy_na=True,\n",
    "\n",
    "input2_dummy = pd.get_dummies(input2, dummy_na=True)\n",
    "input2_dummy.shape\n",
    "input2_dummy.head()\n",
    "input2_dummy.columns\n",
    "\n",
    "input2 = np.array(input2)\n",
    "\n",
    "xgtrain2     = input2_dummy.drop(input2_dummy.columns[[1,2]], axis=1)\n",
    "xgtrain2     = np.array(xgtrain2)\n",
    "xgtrain2     = xgtrain2[0:train.shape[0], :]\n",
    "\n",
    "#label_prob2  = input2[0:train.shape[0], 22]\n",
    "#label_pv2    = input2[0:train.shape[0], 21]\n",
    "xgtest2      = input2_dummy.drop(input2_dummy.columns[[1,2]], axis=1)\n",
    "xgtest2      = np.array(xgtest2)\n",
    "xgtest2      = xgtest2[train.shape[0]:,:]\n",
    "\n",
    "xgtrain2 = xgtrain2.astype(float)\n",
    "#label_prob = label_prob.astype(float)\n",
    "#label_pv = label_pv.astype(float)\n",
    "xgtest2 = xgtest2.astype(float)\n",
    "\n",
    "#End of data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the above 3 models on xgtrain2\n",
    "\n",
    "### Model 4: xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain2_pv = xgb.DMatrix(xgtrain2, label=label_pv)\n",
    "watchlist = [(xgtrain2_pv, 'train')]\n",
    "model_4_xgboost = xgb.train(plst, xgtrain2_pv, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_4_predict = model_4_xgboost.predict(xgb.DMatrix(xgtest2))\n",
    "print max(model_4_predict), min(model_4_predict)\n",
    "model_4_predict[model_4_predict<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_4 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_4_predict})\n",
    "print prediction_4.head()\n",
    "prediction_4.to_csv('Submission/model_4.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse on leaderboard: 565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model 5: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_5_rf = RandomForestRegressor(n_estimators=400, max_depth=8, oob_score=True, n_jobs=6, random_state=123)\n",
    "model_5_rf.fit(xgtrain2, label_pv)\n",
    "print model_5_rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_5_predict = model_5_rf.predict(xgtest2)\n",
    "\n",
    "prediction_5 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_5_predict})\n",
    "print prediction_5.head()\n",
    "prediction_5.to_csv('Submission/model_5.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse on 509.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 6: extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_6_et = ExtraTreesRegressor(n_estimators=750, max_depth=8, oob_score=True, n_jobs=6, random_state=123, verbose=1, bootstrap=True)\n",
    "model_6_et.fit(xgtrain2, label_pv)\n",
    "model_6_predict = model_6_et.predict(xgtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_6 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_6_predict})\n",
    "print prediction_6.head()\n",
    "prediction_6.to_csv('Submission/model_6.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse 496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 7: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_7_ridge = linear_model.Ridge(alpha=0.01)\n",
    "model_7_ridge.fit(xgtrain2, label_pv)\n",
    "model_7_predict = model_7_ridge.predict(xgtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_7 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_7_predict})\n",
    "print prediction_7.head()\n",
    "prediction_7.to_csv('Submission/model_7.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse of 505.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 8: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_8_lasso = linear_model.Lasso()\n",
    "model_8_lasso.fit(xgtrain2, label_pv)\n",
    "model_8_predict = model_8_lasso.predict(xgtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_8 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_8_predict})\n",
    "print prediction_8.head()\n",
    "prediction_8.to_csv('Submission/model_8.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse of 498"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 9: SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_9_sgd = linear_model.SGDRegressor()\n",
    "model_9_sgd.fit(xgtrain2, label_pv)\n",
    "model_9_predict = model_9_sgd.predict(xgtest2)\n",
    "\n",
    "prediction_9 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_9_predict})\n",
    "print prediction_9.head()\n",
    "prediction_9.to_csv('Submission/model_9.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Omit this model. Horrible output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 10: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_10_perceptron = linear_model.Perceptron(penalty=\"l1\", n_iter=250, random_state=123, n_jobs=6)\n",
    "model_10_perceptron.fit(xgtrain2, label_pv)\n",
    "model_10_predict = model_10_perceptron.predict(xgtest2)\n",
    "\n",
    "prediction_10 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_10_predict})\n",
    "print prediction_10.head()\n",
    "prediction_10.to_csv('Submission/model_10.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Omit this model. Takes a long time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model 11: Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_11_kr = KernelRidge(alpha=0.01, kernel='rbf', gamma=0.1)\n",
    "model_11_kr.fit(xgtrain2, label_pv)\n",
    "model_11_predict = model_11_kr.predict(xgtest2)\n",
    "\n",
    "prediction_11 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_11_predict})\n",
    "print prediction_11.head()\n",
    "prediction_11.to_csv('Submission/model_11.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse: 753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model 12: SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_12_svr = KernelRidge(alpha=0.01, kernel='rbf')\n",
    "model_12_svr.fit(xgtrain2, label_pv)\n",
    "model_12_predict = model_12_kr.predict(xgtest2)\n",
    "\n",
    "prediction_12 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_12_predict})\n",
    "print prediction_12.head()\n",
    "prediction_12.to_csv('Submission/model_12.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not going to run this - due to time constraints. Kernel ridge itself took a long time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Stacking\n",
    "\n",
    "Stacking the above 9 models to see if it produces better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_1 = model_1_xgboost.predict(xgb.DMatrix(xgtrain))\n",
    "feature_2 = model_2_rf.predict(xgtrain)\n",
    "feature_3 = model_3_et.predict(xgtrain)\n",
    "feature_4 = model_4_xgboost.predict(xgb.DMatrix(xgtrain2))\n",
    "feature_5 = model_5_rf.predict(xgtrain2)\n",
    "feature_6 = model_6_et.predict(xgtrain2)\n",
    "feature_7 = model_7_ridge.predict(xgtrain2)\n",
    "feature_8 = model_8_lasso.predict(xgtrain2)\n",
    "feature_9 = model_11_kr.predict(xgtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train features\n",
    "train_features = np.vstack((feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9))\n",
    "#Need to transpose features\n",
    "train_features = train_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test features\n",
    "test_features = np.vstack((model_1_predict, model_2_predict, model_3_predict, model_4_predict, model_5_predict, model_6_predict, model_7_predict, model_8_predict, model_11_predict ))\n",
    "#Need to transpose features\n",
    "test_features = test_features.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##First stack model: Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_13_et = ExtraTreesRegressor(n_estimators=750, max_depth=8, oob_score=True, n_jobs=6, random_state=123, verbose=1, bootstrap=True)\n",
    "model_13_et.fit(train_features, label_pv)\n",
    "model_13_predict = model_13_et.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_13 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_13_predict})\n",
    "print prediction_13.head()\n",
    "prediction_13.to_csv('Submission/model_13.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse 696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Second stack model: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_14_ridge = linear_model.Ridge(alpha=0.01)\n",
    "model_14_ridge.fit(train_features, label_pv)\n",
    "model_14_predict = model_14_ridge.predict(test_features)\n",
    "model_14_predict[model_14_predict<0] = 0\n",
    "\n",
    "prediction_14 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_14_predict})\n",
    "print prediction_14.head()\n",
    "prediction_14.to_csv('Submission/model_14.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rmse 740"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Third stack model: Model 3 (Extra Trees) + output features of all the 9 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenating features + train/test dataset\n",
    "xgtrain3 = np.hstack((xgtrain, train_features))\n",
    "xgtest3  = np.hstack((xgtest, test_features))\n",
    "\n",
    "print xgtrain3.shape, xgtest3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_15_et = ExtraTreesRegressor(n_estimators=750, max_depth=8, oob_score=True, n_jobs=6, random_state=123, verbose=1, bootstrap=True)\n",
    "model_15_et.fit(xgtrain3, label_pv)\n",
    "model_15_predict = model_15_et.predict(xgtest3)\n",
    "\n",
    "prediction_15 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_15_predict})\n",
    "print prediction_15.head()\n",
    "prediction_15.to_csv('Submission/model_15.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(model_15_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse 693"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fourth stack model: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_16_ridge = linear_model.Ridge(alpha=0.01)\n",
    "model_16_ridge.fit(xgtrain3, label_pv)\n",
    "model_16_predict = model_16_ridge.predict(xgtest3)\n",
    "model_16_predict[model_16_predict<0] = 0\n",
    "\n",
    "prediction_16 = pd.DataFrame({'ID':test.ID, 'Project_Valuation':model_16_predict})\n",
    "print prediction_16.head()\n",
    "prediction_16.to_csv('Submission/model_16.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rmse 740"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
